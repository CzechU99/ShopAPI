<h2 align="center"><strong>Shop REST API (N-Tier)</strong></h2>

<div align="center">
  <p>
    <img alt="Status" src="https://img.shields.io/badge/status-in%20development-orange">
    <img alt="License" src="https://img.shields.io/badge/license-private-lightgrey">
  </p>
  <p>
    <img alt="Python" src="https://img.shields.io/badge/Python-3776AB?logo=python&logoColor=white">
    <img alt="FastAPI" src="https://img.shields.io/badge/FastAPI-009688?logo=fastapi&logoColor=white">
    <img alt="PostgreSQL" src="https://img.shields.io/badge/PostgreSQL-4169E1?logo=postgresql&logoColor=white">
    <img alt="SQLAlchemy" src="https://img.shields.io/badge/SQLAlchemy-FF0000?logo=sqlalchemy&logoColor=white">
    <img alt="Alembic" src="https://img.shields.io/badge/Alembic-003366?logoColor=white">
    <img alt="Swagger" src="https://img.shields.io/badge/Swagger-85EA2D?logo=swagger&logoColor=black">
    <img alt="Docker" src="https://img.shields.io/badge/Docker-2496ED?logo=docker&logoColor=white">
    <img alt="Postman" src="https://img.shields.io/badge/Postman-FF6C37?logo=postman&logoColor=white">
    <img alt="Pytest" src="https://img.shields.io/badge/Tests-Pytest-5A63F0?logo=pytest&logoColor=white">
    </br>
    <img alt="OpenTelemetry" src="https://img.shields.io/badge/OpenTelemetry-000000?logo=opentelemetry&logoColor=white">
    <img alt="Load Testing" src="https://img.shields.io/badge/Load_Testing-black?logo=speedtest&logoColor=white">
    <img alt="Grafana" src="https://img.shields.io/badge/Grafana-F46800?logo=grafana&logoColor=white">
    <img alt="Prometheus" src="https://img.shields.io/badge/Prometheus-E6522C?logo=prometheus&logoColor=white">
    <img alt="Loki" src="https://img.shields.io/badge/Loki-4A90E2?logo=grafana&logoColor=white">
    <img alt="Tempo" src="https://img.shields.io/badge/Tempo-1F60C4?logo=grafana&logoColor=white">
    <img alt="k6" src="https://img.shields.io/badge/Grafana k6-7D64FF?logo=k6&logoColor=white">
  </p>
</div>

---

## ğŸ¯ Cel projektu

Projekt jest produkcjonopodobnym **REST API sklepu internetowego** w architekturze N-tier, ktÃ³ry umoÅ¼liwia pracÄ™ z relacyjnÄ… bazÄ… danych PostgreSQL. Projekt ma na celu:

#### ETAP I:
- Zaprojektowanie relacyjnego modelu danych z co najmniej **5 tabelami**, obejmujÄ…cymi:
  - â‰¥ 2 relacje jeden-do-wielu  
  - â‰¥ 1 relacjÄ™ wiele-do-wielu (z tabelÄ… poÅ›redniÄ…)  
  - klucze gÅ‚Ã³wne i obce z zachowaniem ON DELETE  
  - unikalne i wymagane pola, ograniczenia CHECK  
  - indeksy dla czÄ™sto wyszukiwanych pÃ³l  
- ImplementacjÄ™ **N-tier API** (API/Presentation â†’ Service/Business â†’ Data Access/Repository â†’ Database)  
- UmoÅ¼liwienie **CRUD** dla przynajmniej 3 encji i odczytu dla pozostaÅ‚ych  
- WalidacjÄ™ danych wejÅ›ciowych i obsÅ‚ugÄ™ bÅ‚Ä™dÃ³w HTTP  
- Wersjonowanie API (np. `/api/v1/...`)  

ObsÅ‚uguje nastÄ™pujÄ…ce encje:
- **Users** â€“ uÅ¼ytkownicy systemu  
- **Products** â€“ produkty w sklepie  
- **Reviews** â€“ recenzje produktÃ³w przez uÅ¼ytkownikÃ³w  
- **Tags** â€“ tagi produktÃ³w  
- **Categories** â€“ kategorie produktÃ³w  
- **Orders** â€“ zamÃ³wienia zÅ‚oÅ¼one przez uÅ¼ytkownikÃ³w 

<br>

#### ETAP II:
- IntegracjÄ™ testÃ³w jednostkowych i integracyjnych z rzeczywistÄ… bazÄ… PostgreSQL (Docker)
- Testy integracyjne z izolowanÄ… bazÄ… testowÄ…, rollback lub czyszczenie po kaÅ¼dym teÅ›cie 

<br>

#### ETAP III:
- Dodanie drugiej usÅ‚ugi HTTP (**External Service**) i wywoÅ‚anie jej z gÅ‚Ã³wnego API w normalnym przepÅ‚ywie (`/api/v1/external/proxy`).
- PeÅ‚na obserwowalnoÅ›Ä‡ **OpenTelemetry** (traces/metrics/logs) + **Grafana + Tempo + Loki + Prometheus**.
- **Correlation ID** generowany dla kaÅ¼dego Å¼Ä…dania w `app`, propagowany do `external_service` i zwracany w odpowiedzi.
- Spany serwerowe FastAPI i klienckie (Requests) z propagacjÄ… kontekstu miÄ™dzy usÅ‚ugami.
- Standardowe HTTP + histogramy opÃ³ÅºnieÅ„ DB (`db_query_duration_seconds`), licznik bÅ‚Ä™dÃ³w zewnÄ™trznej usÅ‚ugi (`ext_service_failures_total`).
- JSON z polami `timestamp, level, message, trace_id, span_id, correlation_id, http.method, http.route, http.status` wysyÅ‚ane do **Loki** (Promtail).

<br>

#### ETAP IV:
Celem etapu byÅ‚o wykonanie serii testÃ³w obciÄ…Å¼eniowych badajÄ…cych:
- OpÃ³Åºnienia po stronie usÅ‚ugi zewnÄ™trznej  
- Timeouty klienta HTTP  
- PresjÄ™ na pulÄ™ poÅ‚Ä…czeÅ„ (max_connections + pool_timeout)  
- Keep-alive i jego wpÅ‚yw na reuse poÅ‚Ä…czeÅ„  
- HTTP/1.1 vs HTTP/2  
- WolnÄ… bazÄ™ danych (spowolniona konfiguracjÄ… + duÅ¼ymi danymi)  

Testy wykonywane poprzez **Grafana k6 z Prometheus Remote Write**, aby pojawiaÅ‚y siÄ™ w Grafanie jako serie metryk `k6_*`.

---

## ğŸ§± Technologie

- **Python 3.11+** â€“ backend  
- **FastAPI** â€“ framework REST API  
- **SQLAlchemy** â€“ ORM do PostgreSQL  
- **Alembic** â€“ migracje schematu bazy danych  
- **PostgreSQL** â€“ relacyjna baza danych  
- **Swagger UI** â€“ dokumentacja i testowanie API  
- **Postman** â€“ testy i kolekcje API  
- **Docker** â€“ konteneryzacja aplikacji i bazy danych  
- **Pytest / Unittest / Testcontainers** â€“ testy jednostkowe i integracyjne  
- **OpenTelemetry** â€“ Å›ledzenie, metryki i logi  
- **Grafana** â€“ wizualizacja (dashboardy, Explore)  
- **Tempo** â€“ magazyn traceâ€™Ã³w  
- **Loki + Promtail** â€“ zbieranie i przeglÄ…d logÃ³w  
- **Prometheus** â€“ metryki aplikacji i bazy  
- **Postgres_exporter** â€“ metryki PostgreSQL  

---

## âš™ï¸ Uruchomienie

a) Skopiuj repozytorium i przejdÅº do katalogu:
   ```bash
   cd ShopAPI
   ```

b) Uruchom:
   ```bash
   docker compose up --build
   ```

c) W kontenerze `app`, aby wgraÄ‡ migracjÄ™ bazy danych:
   ```bash
   docker compose exec app alembic upgrade head
   ```

<br>

Po chwili:
- MAIN API: localhost:8000
- SWAGGER UI: localhost:8000/docs
- DATABASE: localhost:5432 (user: shop | pass: shop | db: shopdb)
- POSTGRESQL ADMIN: localhost:8080 (email: admin@admin.com | pass: admin)
- DB_TEST: localhost:5433 (user: testshop | pass: testshop | db: testshopdb)
- EXTERNAL API: localhost:8001
- PROMETHEUS: localhost:9090
- GRAFANA: localhost:3000 (login: admin / hasÅ‚o: admin)
- TEMPO: localhost:3200
- LOKI API: localhost:3100

---

## ğŸ§ª Testy

- Testy jednostkowe sprawdzajÄ… logikÄ™ serwisÃ³w z mockowanymi repozytoriami.
- Testy integracyjne uruchamiajÄ… siÄ™ na kontenerze PostgreSQL testowym (db_test) i:
  - wykonujÄ… rzeczywiste zapytania SQL
  - uÅ¼ywajÄ… transakcji i rollback po kaÅ¼dym teÅ›cie lub czyszczÄ… dane
  - sÄ… idempotentne i niezaleÅ¼ne od kolejnoÅ›ci uruchamiania
- WeryfikujÄ… m.in.:
  - tworzenie i pobieranie uÅ¼ytkownikÃ³w
  - CRUD produktÃ³w i zamÃ³wieÅ„
  - poprawne przeliczanie kwot zamÃ³wieÅ„
  - zachowanie ograniczeÅ„ bazy danych

<br>

PrzykÅ‚ad uruchomienia testÃ³w:

a) PamiÄ™taj o uruchomieniu kontenera z bazÄ… danych do testÃ³w `db_test`

b) Wykonanie testÃ³w za pomocÄ… polecenia:
```env
docker compose exec app pytest -v
```

---

## ğŸ”­ Observability

- Traces: eksport przez OTLP HTTP do `tempo:4318` (Tempo), spany FastAPI (serwer) i Requests (klient).  
- Metrics: `/metrics` w `app` i `external_service` (Prometheus FastAPI Instrumentator); histogramy DB i licznik bÅ‚Ä™dÃ³w zewnÄ™trznej usÅ‚ugi.  
- Logs: JSON + Promtail â†’ Loki; pola korelacyjne (`trace_id`, `span_id`, `correlation_id`) w kaÅ¼dym logu Å¼Ä…dania.  
- Grafana: gotowy dashboard â€Shop API Observabilityâ€.

<br>

#### Grafana â†’ Explore/Dashboard
- ID gotowych dashboard'Ã³w do importu: PROMETHEUS:18030 | POSTGRES_EXPORTER:9628
- Prometheus: wybierz datasource `Prometheus`, wpisz np. `sum(rate(http_requests_total))`.
- Loki: wybierz `Loki`, filtruj `{container="shop-app-1"}` i zawÄ™Å¼aj po `correlation_id` lub `level`.
- Tempo: wybierz `Tempo`, filtruj `service.name = "main_api"` lub `"external_service"` i przeglÄ…daj traceâ€™y.

---

## ğŸ“ˆ Load Testing (Grafana K6)

#### ğŸŒ Konfigruacja klienta HTTP:

| Zmienna | Opis | DomyÅ›lna wartoÅ›Ä‡ |
| --- | --- | --- |
| `EXT_CLIENT_READ_TIMEOUT` | Timeout na odczyt/odpowiedÅº (w sekundach) | `180` |
| `EXT_CLIENT_CONNECT_TIMEOUT` | Timeout na ustanowienie poÅ‚Ä…czenia TCP | `2` |
| `EXT_CLIENT_WRITE_TIMEOUT` | Timeout na wysÅ‚anie danych (body upload) | `5` |
| `EXT_CLIENT_POOL_TIMEOUT` | Maksymalny czas oczekiwania na wolne poÅ‚Ä…czenie z puli (s) | `0.05` |
| `EXT_CLIENT_MAX_CONNECTIONS` | Maksymalna liczba jednoczesnych poÅ‚Ä…czeÅ„ HTTP (httpx) | `100` |
| `EXT_CLIENT_MAX_KEEPALIVE_CONNECTIONS` | Rozmiar puli keep-alive | `20` |
| `EXT_CLIENT_KEEPALIVE_EXPIRY` | Maksymalny czas bezczynnoÅ›ci poÅ‚Ä…czenia keep-alive (s) | `5` |
| `EXT_CLIENT_HTTP2_ENABLED` | WÅ‚Ä…czenie/wyÅ‚Ä…czenie HTTP/2 (`true` / `false`) | `true` |

<br>

#### ğŸš€ Uruchamianie testÃ³w:
```bash
export K6_PROMETHEUS_RW_SERVER_URL="http://localhost:9090/api/v1/write"
export K6_PROMETHEUS_RW_TREND_STATS="p(95),p(99),min,max"
export K6_PROMETHEUS_RW_TREND_AS_NATIVE_HISTOGRAM="true"   

K6_CASE="case_name" k6 run -o experimental-prometheus-rw --tag testid="test_id_name" tests/k6/lab4.js
```
<br>

#### ğŸ” Analiza wynikÃ³w:
- `k6_http_req_duration{p95,p99}`  
- `k6_http_req_failed`  
- Tempo traces  
- Logi Loki z korelacjÄ… `correlation_id`  
- postgres_exporter:
  - `pg_stat_activity_count`
  - `blks_read_total`
  - `buffers_hit_ratio`

<br>

#### ğŸ—‚ï¸ Wyniki i screeny:
Wszystkie dashboardy, wykresy i logi zostaÅ‚y zebrane w:
```bash
docs/load-tests/
```

<br>

#### ğŸ“ Raport koÅ„cowy:
PeÅ‚ny raport znajduje siÄ™ w:
```
docs/load-tests/REPORT.md
```

---

## ğŸ“¨ Lab 5 â€“ Async Messaging Scenarios

Lab 5 rozszerza architekturÄ™ z Lab 4 o dwa warianty komunikacji asynchronicznej:

- **Scenario A / Async Upstream:** API tylko wrzuca komunikat do kolejki (Kafka lub RabbitMQ) i natychmiast zwraca `202 Accepted`. Worker pobiera wiadomoÅ›Ä‡, wywoÅ‚uje External API i zapisuje wynik w Postgresie.
- **Scenario B / Async Downstream:** API nadal wykonuje poÅ‚Ä…czenie HTTP do External API, ale zapis do bazy zleca poprzez kolejkÄ™ i worker.

### Nowe komponenty

- **Kafka + Zookeeper** â€“ Bitnami images (`kafka:9092`), dwa topiki: `external_async_upstream`, `external_async_downstream`.
- **RabbitMQ** â€“ obraz `rabbitmq:3-management` (`5672`, `15672` UI), dwie kolejki o analogicznych nazwach.
- **Worker (`worker/main.py`)** â€“ wspÃ³Å‚dzielony kod z aplikacjÄ… (SQLAlchemy + `ExternalResultService`). Uruchamiany z parametrami:
  - `MESSAGE_BROKER={kafka|rabbitmq}`
  - `JOB_SCENARIO={async_upstream|async_downstream}`
- **External API bez sztucznego `sleep`** â€“ serwis `external_service` pobiera teraz dane z publicznego API (`jsonplaceholder.typicode.com`) i zwraca realny czas pobrania w polu `remote_delay_ms`.

DomyÅ›lna definicja w `docker-compose.yml` (profil `worker`) odpala worker w trybie `kafka + async_upstream`. PrzykÅ‚ady:

```bash
# Worker dla scenariusza A na Kafka
docker compose --profile worker up worker

# Worker dla scenariusza B na RabbitMQ
MESSAGE_BROKER=rabbitmq JOB_SCENARIO=async_downstream \
  docker compose run --rm worker python worker/main.py
```

### API endpoints

| Endpoint | Opis |
| --- | --- |
| `GET /api/v1/external/proxy` | Baseline z Lab 4 (bez MQ). |
| `POST /api/v1/external/fetch/async-upstream?broker={kafka|rabbitmq}` | Scenario A â€“ zwraca `202` z `correlation_id`. |
| `POST /api/v1/external/fetch/async-downstream?broker={kafka|rabbitmq}` | Scenario B â€“ odpowiedÅº zawiera wynik External API, zapis do DB dzieje siÄ™ asynchronicznie. |

KaÅ¼da Å›cieÅ¼ka propaguje `X-Correlation-Id`, tagi scenariusza oraz dane do Prometheusa/Loki/Tempo.

### k6 â€“ nowe skrypty

Plik `tests/k6/lab5.js` przyjmuje zmienne Å›rodowiskowe:

```bash
K6_SCENARIO=async_upstream \
K6_BROKER=kafka \
K6_CASE="lab5-upstream-kafka" \
k6 run -o experimental-prometheus-rw tests/k6/lab5.js
```

ObsÅ‚ugiwane scenariusze: `baseline`, `async_upstream`, `async_downstream`. Dla wariantÃ³w asynchronicznych ustaw `K6_BROKER` na `kafka` lub `rabbitmq`.

### Dokumentacja i artefakty

- `docs/messaging-load-tests/RESULTS.md` â€“ tabela porÃ³wnawcza (RPS, p50/p95/p99) dla 5 biegÃ³w: baseline, A/B z Kafka i RabbitMQ.
- `docs/messaging-load-tests/*.png` â€“ zrzuty z Grafany (k6 dashboard) oraz para Loki+Tempo z korelacjÄ… `correlation_id`.
- README (ten rozdziaÅ‚) opisuje teÅ¼ jak przeÅ‚Ä…czaÄ‡ brokera i scenariusze.

Po uruchomieniu testÃ³w uzupeÅ‚nij tabelÄ™ wynikÃ³w oraz dodaj screeny zgodnie z wymaganiami labu.

---

> Â© 2025 Shop REST API â€“ Projekt edukacyjny
